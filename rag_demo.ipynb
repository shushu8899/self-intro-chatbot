{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "client = OpenAI()\n",
    "\n",
    "#provide the question to parse in \n",
    "input = \"list me relevant experience\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shuji\\anaconda3.1\\envs\\proj1\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "pc = Pinecone(api_key=getpass.getpass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "#!pip install langchain_pinecone\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "#Recursive character split : divides the input text into smaller chunks of similar sizes in a hierarchical and iterative manner using a set of separators. \n",
    "loader = PyPDFLoader(\"Final resume_Liang Shu-Jing.pdf\")\n",
    "documents= loader.load()\n",
    "string_ = ''\n",
    "for i in range(len(documents)):\n",
    "    string_+=documents[i].page_content\n",
    "string_\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "docs = text_splitter.split_text(string_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"langchain-test-index\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    # With the `text-embedding-3` class\n",
    "    # of models, you can specify the size\n",
    "    # of the embeddings you want returned.\n",
    "    # dimensions=1024\n",
    ")\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding items to vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a345e264-c93b-45e1-aea5-23145b308324',\n",
       " 'e83fec39-d88c-493c-8fe8-5fe3ad8d8ea6',\n",
       " '318c5257-9465-40be-b507-530ba79164d4',\n",
       " '9f8d099d-a8b1-490a-8f39-47ebad80deae',\n",
       " '4c83340b-4baa-4820-aae6-a07337489346',\n",
       " 'a1af1e38-a09b-412c-bb90-486b8011a962',\n",
       " '50b5bcfa-d2b4-40cc-930e-cd5ec911cc6c',\n",
       " '25c7a72f-f72f-485a-941d-4c7e7f84288d',\n",
       " '2a1b5cc2-4ec2-4139-998d-f52b18e69aa0',\n",
       " '54308ccc-1789-4785-8834-23de1d141cd2',\n",
       " '26bb1078-f6f5-4fe0-978c-5b1889b04717',\n",
       " '3f8d0b4a-0190-4e48-8c6e-267b5624fc2c',\n",
       " '06b12442-030b-4337-abd8-596e9fa4ebe0',\n",
       " '34c41138-cd13-442d-a5ec-ad9d3639fc59',\n",
       " 'd4995e46-18b2-4011-aa31-72ffd1548ec9',\n",
       " '4dfec3c3-6bf2-4e3a-9d86-d3c7ccc6c0a0',\n",
       " '61ee78df-eed4-4df4-af37-69de6e47cad9',\n",
       " '505aa78c-5b47-4661-a648-ae3c012e2e47',\n",
       " '3defd95b-903a-497d-8a68-e2889cc7eb1c',\n",
       " 'dd393cee-0a01-4b66-a9ec-c56704066026',\n",
       " 'b3d9b0ed-db46-45e0-9407-a4a0eb41332d',\n",
       " '5bbe49ca-16a0-4b56-8c3b-19108560383e',\n",
       " '18c6cde6-3621-4428-8807-09355ec75e19',\n",
       " 'a0ccd506-3c18-4808-9a71-0c7ba331bae2',\n",
       " '0eb7b90a-7bf0-40ea-bd30-e7d0305442d4',\n",
       " '2999a270-0593-46fc-bd5e-2c7a1c8045b1',\n",
       " '0cd6bf41-12a2-4533-9eb1-607a918ba4d9',\n",
       " 'e15af2ad-81a6-4ff5-8c6a-caa326bfeda0',\n",
       " '7fda91ad-056a-44d6-bde8-721158d69f03',\n",
       " '32c560e0-6121-46b2-bd33-47ccef27898f',\n",
       " '7c5cebac-d19f-4033-9a7d-0282ee787cee',\n",
       " 'cf5db3cb-412c-4fd5-9468-04dd80c398da',\n",
       " '759844f9-c76d-4817-859b-91663b9c0153',\n",
       " 'eaf7fdbd-cae2-429f-8e6a-b734f88daca6',\n",
       " 'd90719ca-5397-49a9-8725-1bcdfc62f635',\n",
       " 'c926768c-01c2-44ac-8496-96308d69a2bb',\n",
       " 'a13b263e-1675-4519-9f31-77073743e254',\n",
       " '6af29e81-e6f0-4e45-8a1e-eafb78e36ad1',\n",
       " '31db810d-fa42-43c4-b9ed-8d51578da5bb',\n",
       " 'c191cb36-c08c-4148-b5e8-99bc311886e7',\n",
       " '387d0c15-89a6-4802-a3d5-7d0f6118fa3e',\n",
       " 'ce8b8aad-1422-40f6-8504-4c2661f5dacd',\n",
       " 'aef4cd52-4077-4e63-b176-419966d85aa5',\n",
       " '341a8c70-3dae-41db-a0ba-90a96edf4ad2',\n",
       " '6c61487f-74b6-4e2c-9dfc-444625f691fe',\n",
       " '8dc379f6-5dfc-4bae-8ec9-0c3670673c40',\n",
       " '65008f27-dc6c-4a0a-a23e-08e9e1432bf0',\n",
       " 'ae4eb6ce-3f72-4837-ab7c-d5cd8afd1e75',\n",
       " 'd42675e4-3509-4b6b-9373-8ce5e279b397',\n",
       " '68bac341-c07c-4f39-aa9d-a61a5db2eae0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = []\n",
    "\n",
    "for i in range(len(docs)):\n",
    "\n",
    "    documents.append(Document(\n",
    "        page_content=docs[i],\n",
    "        metadata={\"source\": \"resume\"},\n",
    "    ))\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'resume', 'text': 'LIANG SHU-JING\\nshujing1999431@gmail.com +65 98557101\\nEDUCATION'}, page_content='LIANG SHU-JING\\nshujing1999431@gmail.com +65 98557101\\nEDUCATION'),\n",
       " Document(metadata={'source': 'resume', 'text': 'EDUCATION\\nSINGAPORE MANAGEMENT UNIVERSITY Jan 2024 - Present'}, page_content='EDUCATION\\nSINGAPORE MANAGEMENT UNIVERSITY Jan 2024 - Present'),\n",
       " Document(metadata={'source': 'resume', 'text': 'Masters of IT in Business (Artificial Intelligence)'}, page_content='Masters of IT in Business (Artificial Intelligence)'),\n",
       " Document(metadata={'source': 'resume', 'text': 'Relevant modules taken : Data science in Business , Applied Machine learning , R statistics for'}, page_content='Relevant modules taken : Data science in Business , Applied Machine learning , R statistics for'),\n",
       " Document(metadata={'source': 'resume', 'text': ', R statistics for Data analysis, Deep'}, page_content=', R statistics for Data analysis, Deep'),\n",
       " Document(metadata={'source': 'resume', 'text': 'learning for visual recognition\\nNATIONAL UNIVERSITY OF SINGAPORE Aug 2018 - Jul 2022'}, page_content='learning for visual recognition\\nNATIONAL UNIVERSITY OF SINGAPORE Aug 2018 - Jul 2022'),\n",
       " Document(metadata={'source': 'resume', 'text': 'Bachelor of Engineering (Chemical Engineering)\\nEXPERIENCE\\nAGILEALGO - Singapore Aug 2024 - Present'}, page_content='Bachelor of Engineering (Chemical Engineering)\\nEXPERIENCE\\nAGILEALGO - Singapore Aug 2024 - Present'),\n",
       " Document(metadata={'source': 'resume', 'text': 'IT consulting focusing on Deep Tech\\nData Science Intern'}, page_content='IT consulting focusing on Deep Tech\\nData Science Intern'),\n",
       " Document(metadata={'source': 'resume', 'text': '\\uf0b7Led the development of an automated document verification process using Convolutional Neural'}, page_content='\\uf0b7Led the development of an automated document verification process using Convolutional Neural'),\n",
       " Document(metadata={'source': 'resume', 'text': 'Neural Networks'}, page_content='Neural Networks'),\n",
       " Document(metadata={'source': 'resume', 'text': '(CNN) and Optical Character Recognition (OCR) techniques to accurately extract text and identify'}, page_content='(CNN) and Optical Character Recognition (OCR) techniques to accurately extract text and identify'),\n",
       " Document(metadata={'source': 'resume', 'text': 'text and identify stamps,'}, page_content='text and identify stamps,'),\n",
       " Document(metadata={'source': 'resume', 'text': 'signatures, and letterhead'}, page_content='signatures, and letterhead'),\n",
       " Document(metadata={'source': 'resume', 'text': '\\uf0b7Utilized integrated AI technologies, including Knowledge Graph Data Science and Large Language'}, page_content='\\uf0b7Utilized integrated AI technologies, including Knowledge Graph Data Science and Large Language'),\n",
       " Document(metadata={'source': 'resume', 'text': 'and Large Language Models (LLM)'}, page_content='and Large Language Models (LLM)'),\n",
       " Document(metadata={'source': 'resume', 'text': 'with Retrieval-Augmented Generation (RAG), to create and expand company’s platform and AI engines'}, page_content='with Retrieval-Augmented Generation (RAG), to create and expand company’s platform and AI engines'),\n",
       " Document(metadata={'source': 'resume', 'text': '\\uf0b7Developed a robust pipeline to optimize delivery of information from production to internal'}, page_content='\\uf0b7Developed a robust pipeline to optimize delivery of information from production to internal'),\n",
       " Document(metadata={'source': 'resume', 'text': 'to internal company database,'}, page_content='to internal company database,'),\n",
       " Document(metadata={'source': 'resume', 'text': 'improving data accessibility and operational efficiency'}, page_content='improving data accessibility and operational efficiency'),\n",
       " Document(metadata={'source': 'resume', 'text': 'EXXONMOBIL ASIA PACIFIC LIMITED - Singapore Jul 2022 - Jun 2024\\nProcess Engineer'}, page_content='EXXONMOBIL ASIA PACIFIC LIMITED - Singapore Jul 2022 - Jun 2024\\nProcess Engineer'),\n",
       " Document(metadata={'source': 'resume', 'text': '\\uf0b7Provided technical support to daily operational issue to mitigate production upset of unmitigated'}, page_content='\\uf0b7Provided technical support to daily operational issue to mitigate production upset of unmitigated'),\n",
       " Document(metadata={'source': 'resume', 'text': 'of unmitigated loss up to `1'}, page_content='of unmitigated loss up to `1'),\n",
       " Document(metadata={'source': 'resume', 'text': 'mil'}, page_content='mil'),\n",
       " Document(metadata={'source': 'resume', 'text': '\\uf0b7Led a cross-functional team in strategic planning and execution of a unit startup, fostering'}, page_content='\\uf0b7Led a cross-functional team in strategic planning and execution of a unit startup, fostering'),\n",
       " Document(metadata={'source': 'resume', 'text': 'startup, fostering collaboration among'}, page_content='startup, fostering collaboration among'),\n",
       " Document(metadata={'source': 'resume', 'text': 'diverse functions to mitigate financial and safety risks. Conducted risk assessments and HAZOP'}, page_content='diverse functions to mitigate financial and safety risks. Conducted risk assessments and HAZOP'),\n",
       " Document(metadata={'source': 'resume', 'text': 'and HAZOP follow-ups'}, page_content='and HAZOP follow-ups'),\n",
       " Document(metadata={'source': 'resume', 'text': '\\uf0b7Conducted an optimization study to facilitate process changes by implementing a Distributed'}, page_content='\\uf0b7Conducted an optimization study to facilitate process changes by implementing a Distributed'),\n",
       " Document(metadata={'source': 'resume', 'text': 'a Distributed Control System'}, page_content='a Distributed Control System'),\n",
       " Document(metadata={'source': 'resume', 'text': '(DCS) , enhanced heat integration, and optimized supply chain strategies to minimize reprocessing'}, page_content='(DCS) , enhanced heat integration, and optimized supply chain strategies to minimize reprocessing'),\n",
       " Document(metadata={'source': 'resume', 'text': 'reprocessing to reduce'}, page_content='reprocessing to reduce'),\n",
       " Document(metadata={'source': 'resume', 'text': 'energy costs in a unit, achieving approximately $500k in savings through lower energy consumption'}, page_content='energy costs in a unit, achieving approximately $500k in savings through lower energy consumption'),\n",
       " Document(metadata={'source': 'resume', 'text': 'HALIBURTON FAR EAST PTE LTD - Singapore Jan 2022 - May 2022\\nProcess Automation Intern'}, page_content='HALIBURTON FAR EAST PTE LTD - Singapore Jan 2022 - May 2022\\nProcess Automation Intern'),\n",
       " Document(metadata={'source': 'resume', 'text': '\\uf0b7Managed data from SQL database to build Power BI reports enhancement across different'}, page_content='\\uf0b7Managed data from SQL database to build Power BI reports enhancement across different'),\n",
       " Document(metadata={'source': 'resume', 'text': 'across different manufacturing'}, page_content='across different manufacturing'),\n",
       " Document(metadata={'source': 'resume', 'text': 'centres (Machine utilization and Load versus Capacity) and identify follow-up actions'}, page_content='centres (Machine utilization and Load versus Capacity) and identify follow-up actions'),\n",
       " Document(metadata={'source': 'resume', 'text': '\\uf0b7Identified cost saving opportunities by comparing vendor pricing comparison across different'}, page_content='\\uf0b7Identified cost saving opportunities by comparing vendor pricing comparison across different'),\n",
       " Document(metadata={'source': 'resume', 'text': 'across different manufacturing'}, page_content='across different manufacturing'),\n",
       " Document(metadata={'source': 'resume', 'text': 'centres globally\\nACADEMIC PROJECTS'}, page_content='centres globally\\nACADEMIC PROJECTS'),\n",
       " Document(metadata={'source': 'resume', 'text': '\\uf0b7Road Crack Detection: Explored image processing techniques, various CNN architecture and tuning to'}, page_content='\\uf0b7Road Crack Detection: Explored image processing techniques, various CNN architecture and tuning to'),\n",
       " Document(metadata={'source': 'resume', 'text': 'and tuning to improve'}, page_content='and tuning to improve'),\n",
       " Document(metadata={'source': 'resume', 'text': 'road crack detection performance'}, page_content='road crack detection performance'),\n",
       " Document(metadata={'source': 'resume', 'text': '\\uf0b7Smart pricing-reasonable rent pricing estimate: Perform data cleansing , feature extraction  and'}, page_content='\\uf0b7Smart pricing-reasonable rent pricing estimate: Perform data cleansing , feature extraction  and'),\n",
       " Document(metadata={'source': 'resume', 'text': 'extraction  and regression'}, page_content='extraction  and regression'),\n",
       " Document(metadata={'source': 'resume', 'text': 'analysis  to predict reasonable rent prices with Airbnb dataset'}, page_content='analysis  to predict reasonable rent prices with Airbnb dataset'),\n",
       " Document(metadata={'source': 'resume', 'text': '\\uf0b7Customer analytics for sports retail: Analyze customer purchasing pattern  by performing customer'}, page_content='\\uf0b7Customer analytics for sports retail: Analyze customer purchasing pattern  by performing customer'),\n",
       " Document(metadata={'source': 'resume', 'text': 'segmentation, market basket analysis, time series analysis and exploratory data analytics'}, page_content='segmentation, market basket analysis, time series analysis and exploratory data analytics'),\n",
       " Document(metadata={'source': 'resume', 'text': 'ADDITIONAL\\n\\uf0b7Programming language: R , Python, SQL, MATLAB'}, page_content='ADDITIONAL\\n\\uf0b7Programming language: R , Python, SQL, MATLAB'),\n",
       " Document(metadata={'source': 'resume', 'text': '\\uf0b7IT skill: Proficient in Microsoft Excel, Microsoft Power point, Microsoft Word, Google Analytics,'}, page_content='\\uf0b7IT skill: Proficient in Microsoft Excel, Microsoft Power point, Microsoft Word, Google Analytics,'),\n",
       " Document(metadata={'source': 'resume', 'text': 'Google Analytics, PowerBI'}, page_content='Google Analytics, PowerBI')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.5},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "include chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "\n",
      "Sh\n",
      "u\n",
      "-J\n",
      "ing\n",
      " has\n",
      " experience\n",
      " working\n",
      " at\n",
      " AG\n",
      "ILE\n",
      "AL\n",
      "GO\n",
      " in\n",
      " Singapore\n",
      " since\n",
      " August\n",
      " \n",
      "202\n",
      "4\n",
      ".\n",
      " Additionally\n",
      ",\n",
      " they\n",
      " are\n",
      " pursuing\n",
      " a\n",
      " Bachelor\n",
      " of\n",
      " Engineering\n",
      " in\n",
      " Chemical\n",
      " Engineering\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Sequence\n",
    "import streamlit as st\n",
    "from langchain_core.messages import HumanMessage\n",
    "import bs4\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "chat_history = []\n",
    "def generate_ans(query, llm):\n",
    "\n",
    "    ### Contextualize question ###\n",
    "    contextualize_q_system_prompt = (\n",
    "        \"Given a chat history and the latest user question \"\n",
    "        \"which might reference context in the chat history, \"\n",
    "        \"formulate a standalone question which can be understood \"\n",
    "        \"without the chat history. Do NOT answer the question, \"\n",
    "        \"just reformulate it if needed and otherwise return it as is.\"\n",
    "    )\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    history_aware_retriever = create_history_aware_retriever(\n",
    "        llm, retriever, contextualize_q_prompt\n",
    "    )\n",
    "\n",
    "\n",
    "    # history_aware_retriever.invoke({\"input\": \"hello\", \"chat_history\": []})\n",
    "\n",
    "    ### Answer question ###\n",
    "    system_prompt = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        \"{context}\"\n",
    "    )\n",
    "    qa_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "    for i in rag_chain.stream({\"input\": query, \"chat_history\": chat_history}):\n",
    "        yield i.get(\"answer\")\n",
    "    # return ai_msg['answer']\n",
    "\n",
    "for i in generate_ans('What experience doe shujing have', llm):\n",
    "    print(i)\n",
    "\n",
    "#     ai_msg= rag_chain.invoke({\"input\": query, \"chat_history\": chat_history}).content[0] #check if need this\n",
    "#     chat_history.extend([HumanMessage(content=question), ai_msg[\"answer\"]])\n",
    "#     return ai_msg, chat_history\n",
    "\n",
    "\n",
    "# # Streamlit UI\n",
    "# st.title(\"Ask me anything\")\n",
    "# openai_api_key = st.sidebar.text_input(\"OpenAI API Key\", type=\"password\")\n",
    "# # chat_history = []\n",
    "# # # User input\n",
    "# # query_in = st.text_input(\"Enter your query:\")\n",
    "# # st.session_state.queries.append(query_in)\n",
    "# # result = generate_ans(query_in)\n",
    "# # st.session_state.results.append(result)\n",
    "\n",
    "\n",
    "\n",
    "# with st.form(\"my_form\"):\n",
    "#     text = st.text_area(\n",
    "#         \"Enter text:\",\n",
    "#         \"What are the three key pieces of advice for learning how to code?\",\n",
    "#     )\n",
    "#     submitted = st.form_submit_button(\"Submit\")\n",
    "#     if not openai_api_key.startswith(\"sk-\"):\n",
    "#         st.warning(\"Please enter your OpenAI API key!\", icon=\"⚠\")\n",
    "#     if submitted and openai_api_key.startswith(\"sk-\"):\n",
    "#         generate_ans(text)\n",
    "\n",
    "\n",
    "# \"chat_history\": [\n",
    "#     HumanMessage(),\n",
    "#     AIMessage(),\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"Ask me anything\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "if prompt := st.chat_input(\"What is up?\"):\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        stream = generate_ans(prompt, llm)\n",
    "        response = st.write_stream(stream)\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
